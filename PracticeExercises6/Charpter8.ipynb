{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 8: Técnicas de validación estadística\n",
    "\n",
    "## Prueba de bondad de ajuste\n",
    "Es una forma de determinar si un conjunto de observaciones proviene de una distribución dada. Es un test de hipótesis, se definen \n",
    "* Hipótesis nula $H_0$. La cual afirma que los datos provienen de una determinada distribución $F$.\n",
    "* Hipótesis alternativa $H_1$. Es la negación de $H_0$.\n",
    "\n",
    "**Estadístico muestral $T = T(X_1, X_2, . . . , X_n)$**: Es una variable aleatoria, que, bajo la hipótesis nula, tiene una distribución conocida o de la cual se saben algunas propiedades. Dada una muestra de datos $X_1 = x_1, X_2 = x_2, . . . , X_n = x_n$, se evalua el estadístico en esta muestra y se toma una decisión de rechazar o no rechazar la hipótesis nula según ”cuán probable” es haber obtenido ese valor. En algunos casos se trata de medir si el valor obtenido es demasiado alto.\n",
    "\n",
    "**p-valor**: Dado un valor obtenido $T=t$ se llama a  $p=P_{H_0}(T \\ge t)$, donde si $p=P_{H_0}(T \\ge t) \\le \\alpha$ se rechaza la hipótesis nula con un nivel de rechazo $\\alpha$. En algunos casos, donde el valor obtenido no es ni muy bajo ni muy alto, se considera $p=\\min\\{P_{H_0}(T \\le t). \\quad P_{H_0}(T ≤ t).$ Las cantidades $p$ se denominan también $p$-valor.\n",
    "\n",
    "**Frecuencia observada**: $N_i=\\#\\{j|Y_j=i,1\\le j\\le n\\}$ es la frecuencia con la que el valor $i$ aparece en la muestra Y.\n",
    "\n",
    "### Test chi cuadrado de Pearson\n",
    "Está dado por: $$T=\\sum_{i=1}^{k}\\frac{(N_i-np_i)^2}{np_i}.$$\n",
    "Si el valor de $T$ es grande, se considera que hay evidencias que la muestra **no proviene** de la distribución $F$, se rechaza la hipótesis nula. Si la hipótesis nula es cierta y $n$ es grande, entonces el estadístico $T$ tiene una distribución $χ$-cuadrado con $k − 1$ grados de libertad, $(χ^2_{k−1})$.\n",
    "Si el nivel de rechazo es del $5\\%$, entonces un $p$-valor menor que $0.05$ es indicativo que la muestra no proviene de la distribución $F$.\n",
    "\n",
    "#### Simulación del $p$-valor\n",
    "Es una forma de ayuda para tomar la desición de rechazar o no la hipótesis cuando el $p$-valor obtenido es muy próximo al nivel de rechazo. Para esto, se simulan muestras de tamaño $n$ de la distribución $F$ y para cada una de ellas se calcula el estadístico $T$. Para un número de simulaciones suficientemente grande, la proporción de valores de $T$ que exceden al valor $T=t_0$ tomado en la muestra original es una buena estimación del $p$-valor.\n",
    "\n",
    "En caso que $n$ sea muy grande en relación a $k$, es conveniente generar directamente las frecuencias observadas. Esto es, supongamos que la variable aleatoria $X$ toma valores $1, 2,. . . , k$, con $p_i = P(X = i)$, entonces se simulan los valores $N_1, N_2, . . . , N_k$.\n",
    "\n",
    "* Como $N_1$ es la cantidad de datos iguales a 1 en una muestra de tamaño $n$, entonces $N_1$ tiene distribución binomial $Bin(n, p_1)$.\n",
    "\n",
    "* Una vez generado $N_1$, se genera $N_2$ que es la cantidad de datos restantes $(n − N_1)$ iguales a 2. Dado que ya se han contado los datos iguales a 1, cada uno de los datos restantes tomará el valor 2 con probabilidad:\n",
    "\n",
    "$$\\lambda_2=P(X=2|X\\ne1)=\\frac{p_2}{1-p_1} \\quad \\Rightarrow \\quad N_2\\sim Bin(n-N_1, \\frac{p_2}{1-p_1}).$$\n",
    "\n",
    "* Los siguientes $n-N_1-N_2$ datos tomarán el valor 3 con probabilidad:\n",
    "\n",
    "$$\\lambda_3=P(X=3|X\\ne1,X\\ne2)=\\frac{p_3}{1-p_1-p_2}.$$\n",
    "\n",
    "* Así siguiendo, las variables $N_j$ condicionadas a los valores obtenidos previamente tienen distribución binomial:\n",
    "\n",
    "$$N_j\\sim Bin(n-\\sum_{i=1}^{j-1}N_i, \\lambda_j), \\quad \\lambda_j=\\frac{p_j}{1-P(X<j)}.$$\n",
    "\n",
    "* Notar que $\\lambda_k=1$, por lo cual $N_k=n-\\sum_{i=1}^{k-1}N_i$.\n",
    "\n",
    "Así, para estimar el $p$-valor, se generan directamente los valores $N_1, N_2, . . . , N_k$ y se calcula el estadístico $T$. Repitiento este proceso un número suficiente de veces, el $p$-valor se calcula como la proporción de valores que superan el valor $T = t$ en la muestra original.\n",
    "\n",
    "#### Parámetros no especificados\n",
    "Las pruebas de bondad de ajuste también pueden aplicarse si los parámetros de la distribución $F$ no son todos conocidos. En este caso, se estima el o los parámetros no especificados. Esto determinará una cierta distribución $\\hat F$. Sea $\\hat p_i = P_{\\hat F}(X = i)$, donde el subíndice indica que $X$ tiene distribución $\\hat F$. El estadístico es en este caso:\n",
    "\n",
    "$$T=\\sum_{i=1}^{k}\\frac{(N_i-n\\hat p_i)^2}{n\\hat p_i}.$$\n",
    "\n",
    "Sea $m$ el número de parámetros que se utilizan para el cálculo de $p_i$ y que deben ser estimados. Es decir, no están especificados. Se puede demostrar que, para $n$ suficientemente grande, el estadístico $T$ tiene aproximadamente una distribución chi-cuadrado con $k − 1 − m$ grados de libertad. En particular, el $p$-valor puede estimarse como:\n",
    "\n",
    "$$p−valor ≈ P(χ^2_{k−1−m} ≥ t).$$\n",
    "\n",
    "En caso de utilizar simulaciones para estimar el $p$-valor, el procedimiento es como sigue:\n",
    "1. Supongamos que la hipótesis nula $H_0$ es que los datos $Y_1, . . . , Y_n$ provienen de una distribución $F$, y asumamos que existen $m$ parámetros de esta distribución que son desconocidos: $\\theta_1, . . . , \\theta_m$.\n",
    "\n",
    "2. A partir de la muestra de datos, se estiman los parámetros obteniendo valores $\\hat \\theta_1, . . . , \\hat \\theta_m$. Esto determina una distribución $\\hat F$ y una probabilidad $\\hat p_i$ para cada valor $i$ de la variable aleatoria. A partir de estas estimaciones se calcula el estadístico  $T$, y llamamos $t$ al valor obtenido.\n",
    "\n",
    "3. En cada simulación, se generan $n$ datos a partir de la distribución $\\hat F$. Luego se vuelven a estimar los parámetros $\\hat \\theta_1, . . . , \\hat \\theta_m$ obteniendo estimaciones $\\hat \\theta_1(sim), . . . , \\hat \\theta_m(sim)$ a partir de la muestra simulada. Estos parámetros determinan una distribución $\\hat F_{sim}$. Con estas estimaciones se calculan las probabilidades $p_i(sim)$, es decir, $p_i(sim) = P_{\\hat F_{sim}}(X = i)$ si $X$ tiene distribución $\\hat F_{sim}$. Luego se calcula el estadístico utilizando las probabilidades $p_i(sim)$:\n",
    "\n",
    "$$T_{sim} = \\sum_{i=1}^{k}\\frac{(N_i − np_i(sim))^2}{np_i(sim)}.$$\n",
    "\n",
    "4. El $p$-valor se estima como la proporción de $T_{sim}$ mayores o iguales a $t$.\n",
    "\n",
    "### Test de Kolmogorov-Smirnov\n",
    "Si las observaciones provienen de datos de tipo continuo, puede aplicarse también el test %\\chi$-cuadrado realizando una discretización. Esto es, pueden agruparse los datos en $k$ intervalos consecutivos:\n",
    "\n",
    "$$(−∞, y_1], (y_1, y_2], (y_2, y_3], . . . ,(y_{k−1},∞),$$\n",
    "\n",
    "y considerar $N_i$ como el número de observaciones en el intervalo $i$, y $p_i$ la probabilidad dada por la distribución $F$ de que la variable esté en el $i$-ésimo intervalo:\n",
    "\n",
    "$$p_0 = F(y_1),$$\n",
    "$$p_i = F(y_i) − F(y_{i−1}), \\quad 1 < i < k,$$\n",
    "$$p_k = 1 − F(y_{k−1}).$$\n",
    "\n",
    "Este método, si bien puede utilizarse, tiene la desventaja de agrupar los datos en intervalos y no considerar como se distribuyen estos datos dentro del intervalo. El test de Kolmogorov-Smirnov resulta más adecuado para datos de tipo continuo.\n",
    "\n",
    "#### Con parámetros no especificados\n",
    "Consideramos al igual que antes una muestra $Y_1, Y_2, . . . , Y_n$ de datos que se suponen independientes, y la hipótesis nula está dada por:\n",
    "\n",
    "$$H_0 : \\text{ los datos provienen de la distribución continua } F.$$\n",
    "\n",
    "En primer lugar se ordenan los datos de menor a mayor. Con $Y(j)$ denotamos al dato que ocupa el $j$-ésimo lugar luego del ordenamiento. Se considera luego la distribución empírica de los datos, $F_e$, donde:\n",
    "\n",
    "$$F_e(x) = \\frac{\\# \\{j | Y_j ≤ x\\}}{n}.$$\n",
    "\n",
    "En particular, si se asumen todos los datos distintos, se tiene que:\n",
    "\n",
    "$$F_e(x) = \\begin{cases} 0 & x < Y(1) \\\\ \\frac{j}{n} & Y(j) ≤ x < Y(j+1), 1 ≤ j < n \\\\ 1 & x ≥ Y(n) \\end{cases}.$$\n",
    "\n",
    "El test de Kolmogorov-Smirnov esencialmente compara la distribución empírica de los datos con la distribución $F$, estimando la distancia máxima entre los dos gráficos. Así, el estadístico de Kolmogorov-Smirnov está dado por:\n",
    "\n",
    "$$D = \\sup_{x\\in\\mathbb{R}} |F_e(x) − F(x)| = \\sup_{x\\in\\mathbb{R}} \\{F_e(x) − F(x), F(x) − F_e(x)\\}.$$\n",
    "\n",
    "Dado que $|F_e(x) − F(x)|$ no es una función continua en todos los reales, no podemos asegurar que alcance un máximo propiamente. Sin embargo, por tomar valores en un subconjunto acotado de $\\mathbb{R}$ podemos garantizar la existencia de un supremo.\n",
    "\n",
    "Como $F_e(Y(n)) = 1$, y $F(x) ≤ 1$ para cualquier $x$, entonces $\\sup_x\\{F_e(x) − F(x)\\}$ es no negativo. Además, como $F$ es monótona creciente en el intervalo donde no vale $0$ ni $1$, entonces $F_e(x)−F(x)$ es decreciente en los intervalos donde $F_e$ es constante. En particular, $F_e(x)−F(x)$ alcanza el máximo en alguno de los $n$ puntos $Y(j)$. Luego:\n",
    "\n",
    "$$\\sup_{x\\in\\mathbb{R}} \\{F_e(x) − F(x)\\} = \\max_{1≤j≤n} \\{ \\frac{j}{n} − F(Y(j)) \\}.$$\n",
    "\n",
    "Por otra parte, $F(x) ≥ 0$ para todo $x$ y $F_e(x) = 0$ si $x < Y(1)$, por lo tanto el máximo de $F(x) − F_e(x)$ es no negativo. Por otra parte, como $F$ es creciente en los intervalos donde $F_e$ es constante, entonces $F(x) − F_e(x)$ tiene una discontinuidad de salto en cada $Y(j)$, y podría decirse que el supremo se alcanza justo antes de un valor $Y(j)$. Este supremo es igual a $F(Y(j))−F_e(Y(j−1))$. Luego:\n",
    "\n",
    "$$\\sup_{x\\in\\mathbb{R}} (F(x) − F_e(x)) = \\max_{1≤j≤n} \\{F(Y(j)) − \\frac{j − 1}{n} \\}.$$\n",
    "\n",
    "Finalmente, el estadístico $D$ en (8.3) puede escribirse como:\n",
    "\n",
    "$$D = \\max_{1≤j≤n} \\left\\{ \\max \\left\\{ \\frac{j}{n} − F(Y(j)), F(Y(j)) − \\frac{j − 1}{n} \\right\\} \\right\\}.$$\n",
    "\n",
    "Bajo la hipótesis $H_0$, el estadístico $D$ sigue una distribución de Kolmogorov, con una expresión bastante compleja y de la cual se tienen algunos valores tabulados para $n→∞$. Por lo tanto, en la práctica es conveniente calcular el $p$-valor con simulaciones. Esto es, realizar $k$ simulaciones de muestras de tamaño $n$ de una variable con distribución $F$, calcular el correspondiente valor del estadístico $D = d_i$ para cada muestra, $1 ≤ i ≤ k$. Finalmente, se estima el $p$-valor a la proporción de valores $d_i$ que exceden al valor $d$:\n",
    "\n",
    "$$p−valor = \\frac{\\# \\{i | d_i > d\\}}{k}.$$\n",
    "\n",
    "Una simplificación de este paso es el hecho que la distribución de $D$ es independiente de la distribución $F$. Esto es, si $Y_1, Y_2, . . . , Y_n$ denota una muestra de tamaño $n$ de una variable con distribución $F$, y $X_1, X_2, . . . , X_n$ denota una muestra de tamaño $n$ de una variable con distribución $G$, y definimos los estadísticos $D_F$ y $D_G$ por:\n",
    "\n",
    "$$D_F = \\max_{1≤j≤n} \\left\\{ \\max \\left\\{ \\frac{j}{n} − F(Y(j)), F(Y(j)) − \\frac{j − 1}{n} \\right\\} \\right\\},$$\n",
    "\n",
    "$$D_G = \\max_{1≤j≤n} \\left\\{ \\max \\left\\{ \\frac{j}{n} − G(X(j)), G(X(j)) − \\frac{j − 1}{n} \\right\\} \\right\\},$$\n",
    "\n",
    "entonces para cualquier $d$ se cumple que:\n",
    "\n",
    "$$P_F(D_F ≥ d) = P_G(D_G ≥ d).$$\n",
    "\n",
    "Resumimos este hecho en el siguiente teorema:\n",
    "\n",
    "**Teorema 8.1**. La probabilidad $P_F(D ≥ d)$ es la misma para cualquier distribución continua $F$.\n",
    "\n",
    "Este teorema permite utilizar muestras a partir de la distribución uniforme en lugar de muestras de distribución $F$: Esto es, una vez observado el estadístico $D = d$ con la muestra $Y_1, Y_2, . . . , Y_n$, se realizan $k$ simulaciones de muestras de tamaño $n$ de una variable uniforme $U ∼ U(0, 1)$. Para cada una de estas muestras simuladas, se calcula el correspondiente estadístico $d_i$, $1 ≤ i ≤ k$. Notemos que para la distribución uniforme, $G(u) = u$ para $u ∈ (0, 1)$. Luego el estadístico $D$ está dado por:\n",
    "\n",
    "$$D = \\max_{1≤j≤n} \\left\\{ \\max \\left\\{ \\frac{j}{n} − U(j), U(j) − \\frac{j − 1}{n} \\right\\} \\right\\}.$$\n",
    "\n",
    "De esta manera, para estimar el $p$-valor a traves de simulaciones es suficiente con generar muestras de tamaño $n$ de variables aleatorias uniformes en $(0, 1)$ y calcular la proporción de valores di que exceden a $d$.\n",
    "\n",
    "#### Parámetros no especificados\n",
    "Si se quiere testear la hipótesis que las observaciones $Y_1, Y_2, . . . , Y_n$ provienen de una distribución $F$ con ciertos parámetros desconocidos, entonces en primer lugar se estiman los parámetros $\\theta_1, \\theta_2, . . . , \\theta_m$, y luego se calcula el estadístico de Kolmogorov-Smirnov:\n",
    "\n",
    "$$D = \\sup_{x\\in\\mathbb{R}} |F_e(x) − F_{\\hat \\theta}(x)|,$$\n",
    "\n",
    "donde $F_e$ es la distribución empírica de los datos, y $F_{\\hat \\theta}$ es la función de distribución obtenida con la estimación de los parámetros $\\theta$. Si el valor de $D$ que se obtiene es $d$, entonces se puede aproximar el $p$-valor como en el caso de parámetros especificados:\n",
    "\n",
    "$$P_{F_{\\hat \\theta}}(D ≥ d) = P_U(D ≥ d),$$\n",
    "\n",
    "donde $U ∼ U(0, 1)$. En caso que el $p$-valor resultara en el área de rechazo ($< 0.05$ por ejemplo), es conveniente realizar una segunda simulación más certera. Más específicamente:\n",
    "\n",
    "1. Se generan $N$ simulaciones de muestras de tamaño $n$, generadas a partir del $F_{\\hat \\theta}$.\n",
    "\n",
    "2. Para cada una de estas muestras $sim$, $1 ≤ sim ≤ N$:\n",
    "\n",
    "$$X_{1,sim}, X_{2,sim}, . . . , X_{n,sim},$$\n",
    "\n",
    "se vuelven a estimar los parámetros. Llamamos $\\hat \\theta_1(sim), \\hat \\theta_2(sim), . . . , \\hat \\theta_m(sim)$. Con estas estimaciones se calcula el estadístico de Kolmogorov-Smirnov a partir de la distribución empírica de la muestra simulada, y la distribución $F_{\\hat \\theta(sim)}$:\n",
    "\n",
    "$$d_{sim} = \\sup_{x\\in\\mathbb{R}} |F_{e,sim}(x) − F_{\\hat \\theta(sim)}(x)|.$$\n",
    "\n",
    "3. La proporción de valores $d_{sim}$ que superen el valor $d$ de la muestra original será la estimación del $p$-valor.\n",
    "\n",
    "## El problema de las dos muestras\n",
    "En una simulación es posible generar valores de una variable aleatoria que sean útiles para el modelo, pero que no necesariamente se conozca su distribución.\n",
    "\n",
    "En general, el problema de las dos muestras considera dos muestras de observaciones que provienen de distribuciones $F_1$ y $F_2$ respectivamente, y se trata de validar la siguiente hipótesis:\n",
    "\n",
    "$$H_0 : \\text{ Las } n + m \\text{ variables } X_1, X_2, . . . , X_n, Y_1, Y_2, . . . , Y_m \\text{ son independientes y provienen de una misma distribución } F.$$\n",
    "\n",
    "Para validar esta hipótesis, consideremos un ordenamiento de las $n + m$ variables y supongamos que todos los elementos son distintos para asegurar que el ordenamiento es único. Si las $n + m$ variables están igualmente distribuidas y son independientes, entonces todos los ordenamientos son equiprobables. Consideremos las variables $X_1, X_2, . . . , X_n$ (Se podría elegir las otras $m$ indistintamente).\n",
    "\n",
    "Denotaremos con $R(X_i)$ a la posición que ocupa el elemento $X_i$ luego del ordenamiento, y $R = \\sum_{i=1}^{n} R(X_i)$.\n",
    "\n",
    "Diremos que $R(X_i)$ es el rango del elemento $X_i$ y $R$ es el rango de la muestra de tamaño $n$. Si se observa el valor $R = r$, y $r$ es un valor muy grande, es indicativo que los valores $X_i$, $1 ≤ i ≤ n$ son en general mayores que los $Y_j$, $1 ≤ j ≤ m$. Analogamente, si $r$ es muy pequeño, esto indica que los valores de los $Y_j$ son mayores que los $X_i$. Como estas dos situaciones dan razón para rechazar la hipótesis nula $H_0$, el $p$-valor estará asociado con las siguientes probabilidades:\n",
    "\n",
    "$$P_{H_0}(R ≥ r), P_{H_0}(R ≤ r).$$\n",
    "\n",
    "Esto es, si alguna de estas probabilidades es muy pequeña se rechaza $H_0$. Así, el $p$-valor se define como:\n",
    "\n",
    "$$p−valor = 2 \\cdot \\min \\{P_{H_0}(R ≥ r), P_{H_0}(R ≤ r)\\}.$$\n",
    "\n",
    "Se toma $2 \\cdot \\min$ porque la región de confianza del $100(1 − α)\\%$ se elige entre dos valores $r_1$ y $r_2$ tales que:\n",
    "\n",
    "$$P_{H_0}(R ≤ r_1) = P_{H_0}(R ≥ r_2) = α/2.$$\n",
    "\n",
    "Así, si el nivel de confianza es $1 − α = 0.90$, entonces la hipótesis nula será rechazada si alguna de las dos probabilidades es menor a $0.05$, o lo que es lo mismo, si dos veces el mínimo es menor a $0.1$.\n",
    "El test de hipótesis que utiliza este $p$-valor se denomina test de suma de rangos, o de Wilcoxon o de Mann-Whitney.\n",
    "\n",
    "### Test de suma de rangos para $n$ y $m$ pequeños \n",
    "\n",
    "Si $n$ y $m$ no son valores grandes y los datos son todos distintos, puede utilizarse una fórmula recursiva para calcular el $p$-valor. Si $n$ o $m$ son grandes, esta fórmula es válida pero poco eficiente.\n",
    "\n",
    "Usaremos la notación:\n",
    "\n",
    "$$P_{n,m}(r) := P(R ≤ r),$$\n",
    "\n",
    "donde los subíndices $n, m$ indican que los datos provienen de dos muestras de tamaño $n$ (primera muestra) y $m$ (segunda muestra) respectivamente, y $R$ es el rango de la muestra de tamaño $n$. La fórmula recursiva se obtiene del siguiente modo. El elemento más grande de los $n + m$ valores pertenece a la primera o a la segunda muestra, y el rango de este elemento es obviamente $n + m$.\n",
    "\n",
    "* Si este elemento pertenece a la primera muestra, entonces el rango de esta muestra es $n + m$ más el rango de los $n − 1$ elementos restantes. Luego, la probabilidad de que $R$ sea menor o igual a $r$ dado que que el mayor elemento esté en la primera muestra es igual a la probabilidad que el rango de los $n − 1$ elementos restantes de la primera muestra sea menor o igual a $r − n − m$:\n",
    "\n",
    "$$P(R ≤ r | \\text{ mayor elemento en la 1ra. muestra}) = P_{n−1,m}(r − m − n).$$\n",
    "\n",
    "* Si el elemento mayor pertenece a la segunda muestra, entonces $R ≤ r$ independientemente que este elemento esté en la segunda muestra o se lo excluya del conjunto total:\n",
    "\n",
    "$$P(R ≤ r | \\text{ mayor elemento en la 2da. muestra}) = P_{n,m−1}(r).$$\n",
    "\n",
    "* Ahora, como el elemento mayor puede estar en la primer muestra con probabilidad $\\frac{n}{n + m}$ y en la segunda con probabilidad $\\frac{m}{n + m}$, entonces:\n",
    "\n",
    "$$P_{n,m}(r) = \\frac{n}{n + m}P_{n−1,m}(r − m − n) + \\frac{m}{n + m}P_{n,m−1}(r).$$\n",
    "\n",
    "Por último, si $n+m = 1$, entonces $R = 1$ en caso que $n = 1$ y $R = 0$ si $m = 1$. Así:\n",
    "\n",
    "$$P_{1,0}(k) = P(R ≤ k) = \\begin{cases} 0 & k < 1 \\\\ 1 & k ≥ 1 \\end{cases}, \\quad P_{0,1}(k) = P(R ≤ k) = \\begin{cases} 0 & k < 0 \\\\ 1 & k ≥ 0 \\end{cases}.$$\n",
    "\n",
    "Por último, como el valor observado $r$ es un número entero, entonces:\n",
    "\n",
    "$$P_{H_0}(R ≥ r) = 1 − P_{H_0}(R < r) = 1 − P_{n,m}(r − 1),$$\n",
    "\n",
    "el $p$-valor puede obtenerse recursivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rangos(n,m,r):\n",
    "    if n == 1 and m == 0:\n",
    "        if r<1:\n",
    "            p = 0.\n",
    "        else:\n",
    "            p = 1.\n",
    "    elif n==0 and m == 1:\n",
    "        if r < 0:\n",
    "            p = 0.\n",
    "        else:\n",
    "            p = 1.\n",
    "    else:\n",
    "        if n == 0:\n",
    "            p = rangos(0,m-1,r)\n",
    "        elif m == 0:\n",
    "            p = rangos(n-1,0,r-n)\n",
    "        else: # n>0, m>0\n",
    "            p = (n*rangos(n-1,m,r-n-m)+m*rangos(n,m-1,r))/(n+m)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La desventaja de este método es que puede implicar un gran número de recursiones. En particular, si elegimos $r$ como el menor de los rangos entre la primera y la segunda muestra, $r$ podría tomar un valor cercano a la mitad de la suma de todos los rangos: $\\frac{(n+m)(n+m+1)}4$. Luego la cantidad de valores de $P_{k,l}(d)$ que deberán efectuarse es del orden de $\\frac{n m (n + m)(n + m + 1)}4$, que para $n = m$ es $O(n^4)$.\n",
    "\n",
    "### Test de suma de rangos para $n$ y $m$ grandes \n",
    "\n",
    "En el caso en que $n$ y $m$ son grandes, se sigue el siguiente procedimiento. Recordemos que:\n",
    "\n",
    "$$R = \\sum_{i=1}^{n} R(X_i).$$\n",
    "\n",
    "Bajo la hipótesis $H_0$, se puede probar que $R$ tiene una distribución aproximadamente normal:\n",
    "\n",
    "$$R ∼ N(E[R], \\sqrt{Var(R)}), \\quad \\text{o bien} \\quad \\frac{R − E[R]}{\\sqrt{Var(R)}} ∼ N(0, 1).$$\n",
    "\n",
    "Tenemos que $R(X_i)$ puede ser cualquier valor entre $1$ y $n + m$, con igual probabilidad. Por lo tanto:\n",
    "\n",
    "$$E[R(X_i)] = \\frac{n + m + 1}2, \\quad E[R] = \\frac{n(n + m + 1)}2.$$\n",
    "\n",
    "Para el cálculo de la varianza, notemos que $R(X_i)$ y $R(X_j)$ no son independientes, en particular porque no pueden tomar simultáneamente el mismo valor. Puede probarse que:\n",
    "\n",
    "$$Var(R(X_i)) = \\frac{(n + m + 1)(n + m − 1)}{12}, \\quad cov(R(X_i), R(X_j)) = −\\frac{n + m + 1}{12}.$$\n",
    "\n",
    "y por lo tanto\n",
    "\n",
    "$$Var(R) = \\sum_{i=1}^{n} Var(R(X_i)) + \\sum_{i≠j} cov(R(X_i), R(X_j)) = \\frac{n (n + m - 1)}{12} - n (n - 1) \\frac{(n + m + 1)}{12} = n m\\frac{n+m+1}{12}.$$\n",
    "\n",
    "Así, bajo la hipótesis nula $H_0$, se tiene que:\n",
    "\n",
    "$$\\frac{R − n(n + m + 1)/2}{\\sqrt{n m (n + m + 1)/12}} \\sim N(0, 1).$$\n",
    "\n",
    "Luego, si $Z ∼ N(0, 1)$ y:\n",
    "\n",
    "$$r^∗ = \\frac{r − n(n + m + 1)/2}{\\sqrt{n m (n + m + 1)/12}},$$\n",
    "\n",
    "entonces el $p$-valor puede calcularse como:\n",
    "\n",
    "$$2 \\min \\{P(Z ≤ r^∗), P(Z ≥ r^∗)\\}.$$\n",
    "\n",
    "Por la propiedad de simetría de $Z$, este mínimo es $P(Z ≤ r^∗)$ si $r^∗ ≤ 0$ y es $P(Z ≥ r^∗)$ en caso contrario. En términos de $r$ esto es:\n",
    "\n",
    "$$p−valor = \\begin{cases} 2P(Z ≤ r^∗) & \\text{ si } r ≤ n\\frac{n+m+1}{2} \\\\ 2P(Z > r^∗) & \\text{ en caso contrario} \\end{cases}.$$\n",
    "\n",
    "SI los $n+m$ datos son todos distintos, entonces todos los ordenamientos son igualmente probables y equivalen a todos los ordenamientos del conjunto de números $\\{1, 2, 3, . . . , n + m\\}$. Por lo tanto, una vez observado el valor $R = r$, el $p$-valor puede determinarse simulando $N$ permutaciones de los primeros $n + m$ números naturales y calculando en cada simulación el valor $R = R(1) + R(2) + · · · + R(n)$. Finalmente:\n",
    "\n",
    "$$p−valor = 2 \\min \\left\\{ \\frac{\\# \\{R | R ≤ r\\}}{N}, \\frac{\\# \\{R | R ≥ r\\}}{N} \\right\\}.$$\n",
    "\n",
    "Por último, si los $n + m$ datos no son todos distintos entonces hay más de un ordenamiento posible y en consecuencia puede haber más de un rango para la muestra de tamaño $n$. En este caso, el rango $R$ se define como el promedio de los rangos de cada ordenamiento.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
